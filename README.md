# ğŸš€ Building Effective Search Systems â€“ HelpMateAI  

## 1. ğŸ“ Background  
This project demonstrates **â€œBuilding Effective Search Systems â€“ HelpMateAIâ€** by leveraging a long life insurance policy document and applying **Retrieval Augmented Generation (RAG)** techniques.  

## 2. ğŸ¯ Problem Statement  
The aim of this project is to design a **robust and reliable generative search system** that can accurately answer questions derived from an insurance policy document.  
For experimentation, we will be working with a single comprehensive life insurance policy file.  

## 3. ğŸ“„ Reference Document  
- The policy document is available here: [Principal-Sample-Life-Insurance-Policy.pdf]  

## 4. ğŸ›  Approach  
The system is structured into **three layers**, each requiring careful design and experimentation.  

### ğŸ”¹ Embedding Layer  
- ğŸ§¹ Preprocess and clean the policy document.  
- ğŸ“ Break the content into meaningful **chunks** for embeddings.  
- ğŸ¤– Experiment with embedding models such as **OpenAI embeddings** or **SentenceTransformers** from HuggingFace.  

### ğŸ”¹ Search Layer  
- ğŸ“ Design at least **three representative queries** based on the policy.  
- ğŸ“‚ Store embeddings in **ChromaDB** and perform semantic search.  
- âš¡ Add a **cache mechanism** to improve efficiency.  
- ğŸ¯ Apply **cross-encoder re-ranking** to enhance retrieval relevance.  

### ğŸ”¹ Generation Layer  
- ğŸ— Construct a carefully engineered **prompt** with retrieved context.  
- âœ… Ensure comprehensive instructions and pass relevant data into the model.  
- âœ¨ Optionally, use **few-shot examples** to refine output quality.  

## 5. ğŸ§© System Layers  

- ğŸ“‘ **Reading & Processing PDFs:** Implemented using [pdfplumber](https://pypi.org/project/pdfplumber/) for structured text, tables, and image extraction.  
- âœ‚ï¸ **Document Chunking:** Start with fixed-size chunking, with scope for improvements.  
- ğŸ”¡ **Embedding Generation:** Use **SentenceTransformer (all-MiniLM-L6-v2)** for embeddings.  
- ğŸ—‚ **ChromaDB Storage:** Efficiently store embeddings for quick retrieval.  
- âš¡ **Semantic Search + Cache:** Introduce a caching mechanism for repeated queries.  
- ğŸ¯ **Re-Ranking:** Use a cross-encoder model to refine the relevance of retrieved results.  
- ğŸ¤– **Retrieval-Augmented Generation:** Feed top results with context to **GPT-3.5** for final answers with citations.  

## 6. ğŸ–¼ System Architecture  
![System Architecture](./Solution_Architecture.png)  

## 7. âš™ï¸ Prerequisites  
- ğŸ Python **3.7+**  
- ğŸ”‘ Add your **OpenAI API Key** to the `OpenAI_API_Key` file.  

## 8. ğŸ“¸ Sample Q&A Demonstrations  
![Sample Questions & Answers](./Sample_Questions_And_Answers.png)  

## 9. ğŸ‘¨â€ğŸ’» Author  
- **Sravana Kumar Sanka**  
